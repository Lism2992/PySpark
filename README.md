# Notebooks de código para procesamiento en Spark.

En este repositorio iré almacenado todo el contenido desarrollado en Spark, tanto en Scala como en PySpark.

Generalmente se utilizará el formato Jupyter Notebook(.ipynb).

El repositorio está pensado para uso y desarrollo personal por lo que muchos de los notebooks de código no están comentados ni optimizados para la comprensión del lector externo. 
